{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM7gCRNmav7FQsBA1iFblUj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoCodeProgram/deepLearning/blob/main/transformer/KD_toy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTGpGwczaUPl",
        "outputId": "2f570cad-8061-4e4b-b512-53ce66877ff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch import Tensor\n",
        "\n",
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transforms_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Loading the CIFAR-10 dataset:\n",
        "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transforms_cifar)\n",
        "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transforms_cifar)\n",
        "#Dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "efWguqArabx2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TeacherNet(nn.Module):\n",
        "    def __init__(self, num_classes: int = 10) -> None:\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        ""
      ],
      "metadata": {
        "id": "wrNjQ6yrac85"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StudentNet(nn.Module):\n",
        "    def __init__(self, num_classes: int = 10) -> None:\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "ERnCY9lfaePW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "\n",
        "# Instantiate the models\n",
        "teacher = TeacherNet(num_classes=100)\n",
        "student = StudentNet(num_classes=100)\n",
        "\n",
        "# Print number of parameters\n",
        "print(f\"TeacherNet parameters: {count_parameters(teacher):,}\")\n",
        "print(f\"StudentNet parameters: {count_parameters(student):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ckBAq8yafw0",
        "outputId": "86e045f4-68b2-48e4-f1e3-9802cac4b5df"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TeacherNet parameters: 1,233,156\n",
            "StudentNet parameters: 290,868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, epochs, learning_rate, device):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "def test(model, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "Ndsrbq3GahKi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "nn_teacher = TeacherNet(num_classes=100).to(device)\n",
        "train(nn_teacher, train_loader, epochs=50, learning_rate=0.001, device=device)\n",
        "test_accuracy_teacher = test(nn_teacher, test_loader, device)\n",
        "print(f\"TeacherNet accuracy: {test_accuracy_teacher:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GC_ywZGailo",
        "outputId": "a8611bef-d822-4e3d-8c4b-c7c68a39f1ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 3.7334867131953335\n",
            "Epoch 2/50, Loss: 2.9585534893736547\n",
            "Epoch 3/50, Loss: 2.5222927709015046\n",
            "Epoch 4/50, Loss: 2.1588439685957774\n",
            "Epoch 5/50, Loss: 1.8657394635434053\n",
            "Epoch 6/50, Loss: 1.5981285140222432\n",
            "Epoch 7/50, Loss: 1.3409642796127164\n",
            "Epoch 8/50, Loss: 1.1029182888415394\n",
            "Epoch 9/50, Loss: 0.89432956156682\n",
            "Epoch 10/50, Loss: 0.7389580313952602\n",
            "Epoch 11/50, Loss: 0.6094782632224414\n",
            "Epoch 12/50, Loss: 0.5176318724240575\n",
            "Epoch 13/50, Loss: 0.44845483132771086\n",
            "Epoch 14/50, Loss: 0.38864142774623267\n",
            "Epoch 15/50, Loss: 0.34081580322615956\n",
            "Epoch 16/50, Loss: 0.32300802981671023\n",
            "Epoch 17/50, Loss: 0.29250525196596067\n",
            "Epoch 18/50, Loss: 0.27106013247857286\n",
            "Epoch 19/50, Loss: 0.2530226032724794\n",
            "Epoch 20/50, Loss: 0.24443763699762674\n",
            "Epoch 21/50, Loss: 0.2425483648038032\n",
            "Epoch 22/50, Loss: 0.22314712439416623\n",
            "Epoch 23/50, Loss: 0.20076901461853056\n",
            "Epoch 24/50, Loss: 0.19686531378146338\n",
            "Epoch 25/50, Loss: 0.19614414178899356\n",
            "Epoch 26/50, Loss: 0.19392238903258527\n",
            "Epoch 27/50, Loss: 0.17822409088590316\n",
            "Epoch 28/50, Loss: 0.18273289524474923\n",
            "Epoch 29/50, Loss: 0.17814948584656326\n",
            "Epoch 30/50, Loss: 0.17108761264505434\n",
            "Epoch 31/50, Loss: 0.1660940668792749\n",
            "Epoch 32/50, Loss: 0.17257713800182148\n",
            "Epoch 33/50, Loss: 0.1557567245421969\n",
            "Epoch 34/50, Loss: 0.16021107384288796\n",
            "Epoch 35/50, Loss: 0.15440324108515466\n",
            "Epoch 36/50, Loss: 0.14961289409167913\n",
            "Epoch 37/50, Loss: 0.13912095154198456\n",
            "Epoch 38/50, Loss: 0.15319111570715904\n",
            "Epoch 39/50, Loss: 0.15175471987043107\n",
            "Epoch 40/50, Loss: 0.13712818724844528\n",
            "Epoch 41/50, Loss: 0.13733008557132312\n",
            "Epoch 42/50, Loss: 0.14303291514896008\n",
            "Epoch 43/50, Loss: 0.1313021852235709\n",
            "Epoch 44/50, Loss: 0.13557032744723316\n",
            "Epoch 45/50, Loss: 0.1325818913589631\n",
            "Epoch 46/50, Loss: 0.13243004280541623\n",
            "Epoch 47/50, Loss: 0.12045266684524868\n",
            "Epoch 48/50, Loss: 0.12450813872701659\n",
            "Epoch 49/50, Loss: 0.12105315701313774\n",
            "Epoch 50/50, Loss: 0.12477825513603735\n",
            "Test Accuracy: 34.70%\n",
            "TeacherNet accuracy: 34.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "nn_student = StudentNet(num_classes=100).to(device)\n",
        "train(nn_student, train_loader, epochs=50, learning_rate=0.001, device=device)\n",
        "test_accuracy_student = test(nn_student, test_loader, device)\n",
        "print(f\"StudentNet accuracy: {test_accuracy_student:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALUb_yyXalTj",
        "outputId": "58e44d63-cad4-4f38-d961-67eb0be1003e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 3.8192296806646855\n",
            "Epoch 2/50, Loss: 3.1824679484172744\n",
            "Epoch 3/50, Loss: 2.8680178291943608\n",
            "Epoch 4/50, Loss: 2.6718322269770565\n",
            "Epoch 5/50, Loss: 2.5298847422307853\n",
            "Epoch 6/50, Loss: 2.41581531203523\n",
            "Epoch 7/50, Loss: 2.3179919452083353\n",
            "Epoch 8/50, Loss: 2.223025311012657\n",
            "Epoch 9/50, Loss: 2.1440253263833573\n",
            "Epoch 10/50, Loss: 2.0677076219295967\n",
            "Epoch 11/50, Loss: 2.0039807089737485\n",
            "Epoch 12/50, Loss: 1.9444994993355809\n",
            "Epoch 13/50, Loss: 1.8809464196769559\n",
            "Epoch 14/50, Loss: 1.8232083624723006\n",
            "Epoch 15/50, Loss: 1.7690415035705178\n",
            "Epoch 16/50, Loss: 1.7162553339588398\n",
            "Epoch 17/50, Loss: 1.6668164651004636\n",
            "Epoch 18/50, Loss: 1.626455647604806\n",
            "Epoch 19/50, Loss: 1.571797754083361\n",
            "Epoch 20/50, Loss: 1.5406977564704663\n",
            "Epoch 21/50, Loss: 1.4951885409501133\n",
            "Epoch 22/50, Loss: 1.4529544376597112\n",
            "Epoch 23/50, Loss: 1.4244558397604494\n",
            "Epoch 24/50, Loss: 1.384601037113034\n",
            "Epoch 25/50, Loss: 1.3452492070441344\n",
            "Epoch 26/50, Loss: 1.3145732180196412\n",
            "Epoch 27/50, Loss: 1.274776011097188\n",
            "Epoch 28/50, Loss: 1.2525416129097646\n",
            "Epoch 29/50, Loss: 1.2170090374289726\n",
            "Epoch 30/50, Loss: 1.190258183649608\n",
            "Epoch 31/50, Loss: 1.1556484279583912\n",
            "Epoch 32/50, Loss: 1.1302380938919223\n",
            "Epoch 33/50, Loss: 1.1067653605524375\n",
            "Epoch 34/50, Loss: 1.0878949128851598\n",
            "Epoch 35/50, Loss: 1.0569572050352485\n",
            "Epoch 36/50, Loss: 1.0406082680030746\n",
            "Epoch 37/50, Loss: 1.0112774895161998\n",
            "Epoch 38/50, Loss: 0.985941330693206\n",
            "Epoch 39/50, Loss: 0.9748626752775542\n",
            "Epoch 40/50, Loss: 0.9577091442687171\n",
            "Epoch 41/50, Loss: 0.9227709189361456\n",
            "Epoch 42/50, Loss: 0.9066103410964109\n",
            "Epoch 43/50, Loss: 0.8907303442152179\n",
            "Epoch 44/50, Loss: 0.8768106656415122\n",
            "Epoch 45/50, Loss: 0.8561658348355975\n",
            "Epoch 46/50, Loss: 0.8427521309682301\n",
            "Epoch 47/50, Loss: 0.8237911760807037\n",
            "Epoch 48/50, Loss: 0.8171385444548666\n",
            "Epoch 49/50, Loss: 0.7936770906861947\n",
            "Epoch 50/50, Loss: 0.7830788727317538\n",
            "Test Accuracy: 33.37%\n",
            "StudentNet accuracy: 33.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "kd_student = StudentNet(num_classes=100).to(device)\n",
        "test_accuracy_light_ce_and_kd = test(kd_student, test_loader, device)\n",
        "\n",
        "\n",
        "def train_knowledge_distillation(teacher, student, train_loader, epochs, learning_rate, T, soft_target_loss_weight, ce_loss_weight, device):\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(student.parameters(), lr=learning_rate)\n",
        "\n",
        "    teacher.eval()  # Teacher set to evaluation mode\n",
        "    student.train() # Student to train mode\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                teacher_logits = teacher(inputs)\n",
        "            student_logits = student(inputs)\n",
        "\n",
        "            soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1)\n",
        "            log_soft_prob = nn.functional.log_softmax(student_logits / T, dim=-1)\n",
        "\n",
        "            # PyTorch's KL divergence: kl_div(log(student_probs), teacher_probs)\n",
        "            soft_targets_loss = nn.functional.kl_div(\n",
        "                input=log_soft_prob,\n",
        "                target=soft_targets,\n",
        "                reduction='batchmean',\n",
        "                log_target=False\n",
        "            ) * (T**2)\n",
        "            # Calculate the true label loss\n",
        "            label_loss = ce_loss(student_logits, labels)\n",
        "\n",
        "            # Weighted sum of the two losses\n",
        "            loss = soft_target_loss_weight * soft_targets_loss + ce_loss_weight * label_loss\n",
        "            loss.backward()\n",
        "            loss_detached = loss.item()\n",
        "            running_loss += loss_detached\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "# Apply ``train_knowledge_distillation`` with a temperature of 2. Arbitrarily set the weights to 0.75 for CE and 0.25 for distillation loss.\n",
        "train_knowledge_distillation(teacher=nn_teacher, student=kd_student, train_loader=train_loader, epochs=50, learning_rate=0.001, T=3, soft_target_loss_weight=0.75, ce_loss_weight=0.25, device=device)\n",
        "test_accuracy_light_ce_and_kd = test(kd_student, test_loader, device)\n",
        "\n",
        "# Compare the student test accuracy with and without the teacher, after distillation\n",
        "print(f\"Teacher accuracy: {test_accuracy_teacher:.2f}%\")\n",
        "print(f\"Student accuracy without teacher: {test_accuracy_student:.2f}%\")\n",
        "print(f\"Student accuracy with CE + KD: {test_accuracy_light_ce_and_kd:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgF-NfCEanrT",
        "outputId": "4d0c086a-4363-4f3b-a525-04c322d95c07"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 1.17%\n",
            "Epoch 1/50, Loss: 22.434488432747976\n",
            "Epoch 2/50, Loss: 18.77685026246674\n",
            "Epoch 3/50, Loss: 17.099019264688298\n",
            "Epoch 4/50, Loss: 15.85963968841397\n",
            "Epoch 5/50, Loss: 14.981711781754786\n",
            "Epoch 6/50, Loss: 14.310633056017817\n",
            "Epoch 7/50, Loss: 13.764878540622945\n",
            "Epoch 8/50, Loss: 13.322368402870334\n",
            "Epoch 9/50, Loss: 12.906310018228025\n",
            "Epoch 10/50, Loss: 12.562101422523966\n",
            "Epoch 11/50, Loss: 12.211317373781789\n",
            "Epoch 12/50, Loss: 11.915000020241251\n",
            "Epoch 13/50, Loss: 11.634519182905859\n",
            "Epoch 14/50, Loss: 11.39661893066095\n",
            "Epoch 15/50, Loss: 11.129178047180176\n",
            "Epoch 16/50, Loss: 10.91696605390432\n",
            "Epoch 17/50, Loss: 10.687643343088578\n",
            "Epoch 18/50, Loss: 10.473919377035024\n",
            "Epoch 19/50, Loss: 10.21887799671718\n",
            "Epoch 20/50, Loss: 10.076169330246595\n",
            "Epoch 21/50, Loss: 9.901280466391116\n",
            "Epoch 22/50, Loss: 9.667597240331222\n",
            "Epoch 23/50, Loss: 9.547943446100975\n",
            "Epoch 24/50, Loss: 9.370908420913073\n",
            "Epoch 25/50, Loss: 9.238973079895487\n",
            "Epoch 26/50, Loss: 9.07460560847302\n",
            "Epoch 27/50, Loss: 8.940342679315684\n",
            "Epoch 28/50, Loss: 8.824022193344272\n",
            "Epoch 29/50, Loss: 8.667016671628367\n",
            "Epoch 30/50, Loss: 8.554910068609276\n",
            "Epoch 31/50, Loss: 8.446615279937276\n",
            "Epoch 32/50, Loss: 8.314755875237134\n",
            "Epoch 33/50, Loss: 8.198997193453263\n",
            "Epoch 34/50, Loss: 8.098199963569641\n",
            "Epoch 35/50, Loss: 8.001439413245844\n",
            "Epoch 36/50, Loss: 7.897847036926114\n",
            "Epoch 37/50, Loss: 7.77034833723185\n",
            "Epoch 38/50, Loss: 7.694282976948485\n",
            "Epoch 39/50, Loss: 7.618785262107849\n",
            "Epoch 40/50, Loss: 7.552086800945048\n",
            "Epoch 41/50, Loss: 7.4287867351454135\n",
            "Epoch 42/50, Loss: 7.334388993224319\n",
            "Epoch 43/50, Loss: 7.239841908824687\n",
            "Epoch 44/50, Loss: 7.200867570176417\n",
            "Epoch 45/50, Loss: 7.130814274963067\n",
            "Epoch 46/50, Loss: 7.077392794647995\n",
            "Epoch 47/50, Loss: 7.0220089396651915\n",
            "Epoch 48/50, Loss: 6.933775563629306\n",
            "Epoch 49/50, Loss: 6.86313300959918\n",
            "Epoch 50/50, Loss: 6.80275961574243\n",
            "Test Accuracy: 36.89%\n",
            "Teacher accuracy: 34.70%\n",
            "Student accuracy without teacher: 33.37%\n",
            "Student accuracy with CE + KD: 36.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sZOAx88kcLOD"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}